---
output:
  html_document: default
  pdf_document: default
---
# Assignment 1
## Biomedical Data Science
## B159640

### Problem 1

Loading library to work with data tables
```{r}
library(data.table)
```

Loading the electronic health record data from the study cohort
```{r}
cohort <- read.csv("assignment1_data/cohort.csv", stringsAsFactors = TRUE)
lab <- read.csv("assignment1_data/lab1.csv")
linker <- read.csv("assignment1_data/linker.csv", stringsAsFactors = TRUE)
```

#### Problem 1 (a)

Converting data frames to data tables and exclude the `yob` field in `cohort` to ensure that only one yob field remains in the final data table
```{r}
cohort.dt <- data.table(cohort)
lab.dt <- data.table(lab)[,!"yob"] 
linker.dt <- data.table(linker)
```

Merging `cohort` and `lab` dataset using the `linker` dataset to create a single data table based dataset `cohort.dt`
```{r}
cohort.dt <- merge(cohort.dt, linker.dt, by.x = "id", by.y = "id")
cohort.dt <- merge(cohort.dt, lab.dt, by.x = "LABID", by.y = "LABID")
```

Ensuring that the `albumin` field is converted to a factor:
We ensured that when reading the `.csv` files into R and specified `stringsAsFactors = TRUE`, but we will check it again:
```{r}
is.factor(cohort.dt$albumin)
```

Ensuring that the ordering of the factor is 1=“normo”,2=“micro”,3=“macro”:
```{r}
cohort.dt$albumin <- relevel(cohort.dt$albumin, "macro")
cohort.dt$albumin <- relevel(cohort.dt$albumin, "micro")
cohort.dt$albumin <- relevel(cohort.dt$albumin, "normo")

table(cohort.dt$albumin)
```

Ensuring the `diabetes` field is field is converted to a factor, too:
```{r}
cohort.dt[, diabetes := as.factor(diabetes)]
```

Performing assertion checks:
* to ensure that all identifiers in cohort.csv have been accounted for
* to ensure that any validation fields are consistent between sets
```{r}
stopifnot(all(cohort.dt$id %in% cohort$id))

setorder(cohort.dt, id)
setorder(linker.dt, id)
stopifnot(all(cohort.dt[,id, LABID] == linker.dt[,id, LABID]))
```

Dropping the identifier that originated from lab dataset LABID
```{r}
cohort.dt$LABID <- NULL
```

#### Problem 1 (b)

Calculating the age/year offset:
```{r}
age.offset <- mean(cohort.dt$yob + cohort.dt$age, na.rm=TRUE)
```

Updating any missing age fields based on age/year offset:
```{r}
cohort.dt[, age := ifelse(is.na(age), age.offset-yob, age)]
```

#### Problem 1 (c) and (d)

Creating a separate data table to provide a summary of the data in the `cohort.dt` table.
It contains a row for each column in the `cohort.dt` table and the following columns:
* variable name
* Median (Interquartile Range) for continuous non-categorical data and N (%) for cate-
gorical
* Total N
* Missing N (%)

Creating a function that takes a vector of numeric or integer values and returns a character string of the median and interquartile range. The functions accepts a boolean parameter `impute.to.mean` to impute any missing values to the mean value of the vector. Its default value is set to `FALSE`:
```{r}
return.median.plus.iqr <- function(vector, impute.to.mean=FALSE){
  
  if(impute.to.mean==TRUE){
    # find missing values
    na.idx <- is.na(vector)
    # replace NAs with the median
    vector[na.idx] <- mean(vector, na.rm=TRUE)
  }
  
  # calculate the mean
  v.mean <- round( median(vector, na.rm = TRUE),2)
  # calculate the interquartile range
  v.iqr <- round( quantile(vector, c(0.25, 0.75), na.rm = TRUE),2)
  # format output so that it is a string with form “12 (11,13)”
  output <- paste0(v.mean, " (", v.iqr[1],",",v.iqr[2],")")
  
  return(output)
}
```

Performing the function on all `cohort.dt` columns with continuous values and using the result to calculate the summary table for all continuous variables:
```{r}
summary.con.variables <- data.table("Variable" = colnames(cohort.dt[, .SD, .SDcols = sapply(cohort.dt, is.numeric)]),
                                    "Median (IQR) or N (%)" = sapply(cohort.dt[, .SD, .SDcols = sapply(cohort.dt, is.numeric)], return.median.plus.iqr),
                                    "Total N" = sapply(cohort.dt[, .SD, .SDcols = sapply(cohort.dt, is.numeric)], length),
                                    "Missing N (%)" = sapply(cohort.dt[, .SD, .SDcols = sapply(cohort.dt, is.numeric)], function(z)sum(is.na(z))/length(z)*100))
```

Splitting categorical fields in the summary table into a row per category. Creating a function that takes a vector of categorical values as an input and returns the total number of non-missing rows of the respective factor and the overall percentage of the respective factor:
```{r}
return.summary.cat <- function(vector, use.str){
  
  # calculate total number of non-missing rows of the factor category
  cat.N <- length( vector[which(vector == use.str )])
  # calculate overall percentage of non-missing rows of the factor category based on the input vector
  cat.perc <- round( cat.N / length(vector) * 100, 2 )
   # format output so that it is a string with form “12 (5%)”
  output <- paste0( cat.N, " (", cat.perc, ")")
  return(output)
}
```

Using this function to compute the total number of non-missing rows of the `albumin` and `diabetes` categories and the overall percentage of the `albumin` and `diabetes` categories:
```{r}
per.cat.N <- c( return.summary.cat(cohort.dt$diabetes, 0),
                return.summary.cat(cohort.dt$diabetes, 1),
                return.summary.cat(cohort.dt$albumin, "normo"),
                return.summary.cat(cohort.dt$albumin, "micro"),
                return.summary.cat(cohort.dt$albumin, "macro"))
```

Computing the remaining values for the summary table of the categorial variables
```{r}
cat.missing.N <- format(round(sapply(cohort.dt[, c("diabetes","albumin")], function(z)sum(is.na(z))/length(z)*100),2), nsmall = 2)
cat.total.N <- sapply(cohort.dt[, c("diabetes","albumin")], length)
```

Creating the summary table for all non-continuous variables:
```{r}
summary.cat.variables <- data.table("Variable" = c("diabetes (0)","diabetes(1)","albumin (normo)","albumin (micro)","albumin (macro)"),
                                    "Median (IQR) or N (%)" = per.cat.N,
                                    "Total N" = c(rep(cat.total.N[1],2),rep(cat.total.N[2],3)),
                                    "Missing N (%)" = c(rep(cat.missing.N[1],2),rep(cat.missing.N[2],3)))
```

Combining the results in one summary data table listing both the continuous and categorical variables:
```{r}
summary.cohort.dt <- rbind(summary.con.variables, summary.cat.variables)
summary.cohort.dt
```

### Problem 2

Loading the `data.table` library and importing the required data sets
```{r}
library(data.table)

gfr.1 <- read.csv("assignment1_data/ltegfr1.csv", stringsAsFactors = TRUE)
gfr.2 <- read.csv("assignment1_data/ltegfr2.csv", stringsAsFactors = TRUE)
```

#### Problem 2 (a)

Converting the files to data tables and merge in an appropriate way into a single data table
```{r}
eGFR.dt <- merge( data.table(gfr.1),
                 data.table(gfr.2),
                 by.x = c("id","fu.years"), 
                 by.y = c("ID","fu.years"),
                 all = TRUE )
```

Ordering the observations according to subject identifier and follow-up time
```{r}
setorderv(eGFR.dt, c("id","fu.years"), c(1,1))
```

Adding an assertion that the ordering is correct

```{r}
stopifnot( all(eGFR.dt[, c("id", "fu.years")] == eGFR.dt[order(id, fu.years), fu.years, by = id] ))
```

#### Problem 2 (b)

Computing the average eGFR and length of follow-up for each patient:
```{r}
summary.egfr.table <- NULL

# creating bins for eGFR ranges:
CKD.stage.1 <- 0
CKD.stage.2 <- 0
CKD.stage.3 <- 0
CKD.stage.4 <- 0
CKD.stage.5 <- 0

# creating bin for missing average eGFR
missing.avg.egfr <- 0

for (pat.id in 1:max(eGFR.dt$id)){
  
  # calculate average eGFR for each patient
  avg.egfr <- mean(eGFR.dt[id == pat.id]$egfr)
  
  # calculate average follow-up for each patient
  avg.fu.years <- mean(eGFR.dt[id == pat.id]$fu.years)
  
  # create a summary table
  summary.egfr.table <- rbind(summary.egfr.table, c(pat.id, avg.egfr, avg.fu.years))
  
  # increment the respective bin counter by 1
  if ( is.na(avg.egfr) ){
    missing.avg.egfr <- missing.avg.egfr + 1
  } else if (avg.egfr > 0 && avg.egfr <= 15){
    CKD.stage.5 <- CKD.stage.5 + 1
  } else if (avg.egfr > 15 && avg.egfr <= 30){
    CKD.stage.4 <- CKD.stage.4 + 1
  } else if (avg.egfr > 30 && avg.egfr <= 60){
    CKD.stage.3 <- CKD.stage.3 + 1
  } else if (avg.egfr > 60 && avg.egfr <= 90){
    CKD.stage.2 <- CKD.stage.2 + 1
  } else if (avg.egfr > 90){
    CKD.stage.1 <- CKD.stage.1 + 1
  }
}

colnames(summary.egfr.table) <- c("pat.id", "avg.gfr", "avg.fu.years") # assign colnames to table
summary.egfr.dt <- data.table(summary.egfr.table) # create data.table
head(summary.egfr.dt)
```

Tabulating the number of patients with average eGFR in the following ranges:
(0, 15], (15, 30], (30, 60], (60, 90], (90, ∞)
```{r}
CKD.stages.dt <- data.table("CKD stage" = c("I","II","III","IV","V"), 
                            "N Patients" = c(CKD.stage.1, CKD.stage.2, CKD.stage.3, CKD.stage.4, CKD.stage.5))

CKD.stages.dt
```

Counting and reporting the number of patients with missing average eGFR:
```{r}
# first, assert that our count was correct
stopifnot(sum(is.na(summary.egfr.dt$avg.gfr)) == missing.avg.egfr)
# number of patients with missing average eGFR
sum(is.na(summary.egfr.dt$avg.gfr))
```

Ensuring that the table ordering is returned to id, and follow-up time:
Check `eGFR.dt` and `summary.egfr.dt` table:
```{r}
# eGFR.dt
setorderv(eGFR.dt, c("id","fu.years"), c(1,1))
stopifnot( all(eGFR.dt[, c("id", "fu.years")] == eGFR.dt[order(id, fu.years), fu.years, by = id] ))

# summary.egfr.dt
setorderv(summary.egfr.dt, c("pat.id","avg.fu.years"), c(1,1))
stopifnot( all(summary.egfr.dt[, c("pat.id", "avg.fu.years")] == summary.egfr.dt[order(pat.id, avg.fu.years), avg.fu.years, by = pat.id]))
```

Fitting a linear regression model for the eGFR measurements as a function of time 
for each patient with at least 3 eGFR readings and store it in the `summary.egfr.dt` data table
```{r}
# create empty vector
lr.models <- vector(mode="list", length=max(eGFR.dt$id))

# loop over all patients in eGFR data table
for (pat.id in 1:max(eGFR.dt$id)){
  
  # check whether patient has at least 3 eGFR readings
  if (sum(!is.na(eGFR.dt[id == pat.id]$egfr)) >= 3){
    # fit LR model
    regr.egfr <- lm(egfr ~  fu.years, data = eGFR.dt[id == pat.id], na.action = na.omit)
  } else {
    regr.egfr <- NA
  }
  
  lr.models[[pat.id]] <- regr.egfr
  
}

# add LR models to the summary data table
summary.egfr.dt <- cbind(summary.egfr.dt, lr.models)
```

Counting how many patients have a slope < -3, [-3, 0), [0, 3], > 3
```{r}
# Creating slope bins
slope.1 <- 0 # < -3
slope.2 <- 0 # [-3, 0)
slope.3 <- 0 # [0, 3]
slope.4 <- 0 # > 3

# Looping over entries of summary data table
for (id in 1:max(summary.egfr.dt$pat.id)){
  
  # check whether LR model exists
  if (!is.na(summary.egfr.dt[pat.id == id ]$lr.models)){
    
    # assign slope of the model to variable
    slope <- coef(summary.egfr.dt[pat.id == id ]$lr.models[[1]])[2]
    
    # increment the respective bin counter by 1
    if (slope < -3){
      slope.1 <- slope.1 + 1
    } else if (slope >= -3 && slope < 0){
      slope.2 <- slope.2 + 1
    } else if (slope >= 0 && slope <= 3){
      slope.3 <- slope.3 + 1
    } else if (slope > 3){
      slope.4 <- slope.4 + 1
    }
  }
}

# create data table
slopes.dt <- data.table("slope" = c("< -3","[-3, 0)","[0, 3]","> 3"), 
                        "N Patients" = c(slope.1, slope.2, slope.3, slope.4))
slopes.dt
```

#### Problem 2 (c)

#### Problem 2 (d)

### Problem 3

### Problem 4