---
output:
  html_document: default
  pdf_document: default
---
# Assignment 1
## Biomedical Data Science
## B159640

### Problem 1

Loading library to work with data tables
```{r}
library(data.table)
```

Loading the electronic health record data from the study cohort
```{r}
cohort <- read.csv("assignment1_data/cohort.csv", stringsAsFactors = TRUE)
lab <- read.csv("assignment1_data/lab1.csv")
linker <- read.csv("assignment1_data/linker.csv", stringsAsFactors = TRUE)
```

#### Problem 1 (a)

Converting data frames to data tables and exclude the `yob` field in `cohort` to ensure that only one yob field remains in the final data table
```{r}
cohort.dt <- data.table(cohort)
lab.dt <- data.table(lab)[,!"yob"] 
linker.dt <- data.table(linker)
```

Merging `cohort` and `lab` dataset using the `linker` dataset to create a single data table based dataset `cohort.dt`
```{r}
cohort.dt <- merge(cohort.dt, linker.dt, by.x = "id", by.y = "id")
cohort.dt <- merge(cohort.dt, lab.dt, by.x = "LABID", by.y = "LABID")
```

Ensuring that the `albumin` field is converted to a factor:
We ensured that when reading the `.csv` files into R and specified `stringsAsFactors = TRUE`, but we will check it again:
```{r}
is.factor(cohort.dt$albumin)
```

Ensuring that the ordering of the factor is 1=“normo”,2=“micro”,3=“macro”:
```{r}
cohort.dt$albumin <- relevel(cohort.dt$albumin, "macro")
cohort.dt$albumin <- relevel(cohort.dt$albumin, "micro")
cohort.dt$albumin <- relevel(cohort.dt$albumin, "normo")

table(cohort.dt$albumin)
```

Ensuring the `diabetes` field is field is converted to a factor, too:
```{r}
cohort.dt[, diabetes := as.factor(diabetes)]
```

Performing assertion checks:

* to ensure that all identifiers in cohort.csv have been accounted for
* to ensure that any validation fields are consistent between sets
```{r}
stopifnot(all(cohort.dt$id %in% cohort$id))

setorder(cohort.dt, id)
setorder(linker.dt, id)
stopifnot(all(cohort.dt[,id, LABID] == linker.dt[,id, LABID]))
```

Dropping the identifier that originated from lab dataset LABID
```{r}
cohort.dt$LABID <- NULL
```

#### Problem 1 (b)

Calculating the age/year offset:
```{r}
age.offset <- mean(cohort.dt$yob + cohort.dt$age, na.rm=TRUE)
```

Updating any missing age fields based on age/year offset:
```{r}
cohort.dt[, age := ifelse(is.na(age), age.offset-yob, age)]
```

#### Problem 1 (c) and (d)

Creating a separate data table to provide a summary of the data in the `cohort.dt` table.
It contains a row for each column in the `cohort.dt` table and the following columns:

* variable name
* Median (Interquartile Range) for continuous non-categorical data and N (%) for cate-
gorical
* Total N
* Missing N (%)

Creating a function that takes a vector of numeric or integer values and returns a character string of the median and interquartile range. The functions accepts a boolean parameter `impute.to.mean` to impute any missing values to the mean value of the vector. Its default value is set to `FALSE`:
```{r}
return.median.plus.iqr <- function(vector, impute.to.mean=FALSE){
  
  if(impute.to.mean==TRUE){
    # find missing values
    na.idx <- is.na(vector)
    # replace NAs with the median
    vector[na.idx] <- mean(vector, na.rm=TRUE)
  }
  
  # calculate the mean
  v.mean <- round( median(vector, na.rm = TRUE),2)
  # calculate the interquartile range
  v.iqr <- round( quantile(vector, c(0.25, 0.75), na.rm = TRUE),2)
  # format output so that it is a string with form “12 (11,13)”
  output <- paste0(v.mean, " (", v.iqr[1],",",v.iqr[2],")")
  
  return(output)
}
```

Performing the function on all `cohort.dt` columns with continuous values and using the result to calculate the summary table for all continuous variables:
```{r}
summary.con.variables <- data.table("Variable" = colnames(cohort.dt[, .SD, .SDcols = sapply(cohort.dt, is.numeric)]),
                                    "Median (IQR) or N (%)" = sapply(cohort.dt[, .SD, .SDcols = sapply(cohort.dt, is.numeric)], return.median.plus.iqr),
                                    "Total N" = sapply(cohort.dt[, .SD, .SDcols = sapply(cohort.dt, is.numeric)], length),
                                    "Missing N (%)" = sapply(cohort.dt[, .SD, .SDcols = sapply(cohort.dt, is.numeric)], function(z)sum(is.na(z))/length(z)*100))
```

Splitting categorical fields in the summary table into a row per category. Creating a function that takes a vector of categorical values as an input and returns the total number of non-missing rows of the respective factor and the overall percentage of the respective factor:
```{r}
return.summary.cat <- function(vector, use.str){
  
  # calculate total number of non-missing rows of the factor category
  cat.N <- length( vector[which(vector == use.str )])
  # calculate overall percentage of non-missing rows of the factor category based on the input vector
  cat.perc <- round( cat.N / length(vector) * 100, 2 )
   # format output so that it is a string with form “12 (5%)”
  output <- paste0( cat.N, " (", cat.perc, ")")
  return(output)
}
```

Using this function to compute the total number of non-missing rows of the `albumin` and `diabetes` categories and the overall percentage of the `albumin` and `diabetes` categories:
```{r}
per.cat.N <- c( return.summary.cat(cohort.dt$diabetes, 0),
                return.summary.cat(cohort.dt$diabetes, 1),
                return.summary.cat(cohort.dt$albumin, "normo"),
                return.summary.cat(cohort.dt$albumin, "micro"),
                return.summary.cat(cohort.dt$albumin, "macro"))
```

Computing the remaining values for the summary table of the categorial variables
```{r}
cat.missing.N <- format(round(sapply(cohort.dt[, c("diabetes","albumin")], function(z)sum(is.na(z))/length(z)*100),2), nsmall = 2)
cat.total.N <- sapply(cohort.dt[, c("diabetes","albumin")], length)
```

Creating the summary table for all non-continuous variables:
```{r}
summary.cat.variables <- data.table("Variable" = c("diabetes (0)","diabetes(1)","albumin (normo)","albumin (micro)","albumin (macro)"),
                                    "Median (IQR) or N (%)" = per.cat.N,
                                    "Total N" = c(rep(cat.total.N[1],2),rep(cat.total.N[2],3)),
                                    "Missing N (%)" = c(rep(cat.missing.N[1],2),rep(cat.missing.N[2],3)))
```

Combining the results in one summary data table listing both the continuous and categorical variables:
```{r}
summary.cohort.dt <- rbind(summary.con.variables, summary.cat.variables)
summary.cohort.dt
```

### Problem 2

Loading the `data.table` library and importing the required data sets
```{r}
library(data.table)

gfr.1 <- read.csv("assignment1_data/ltegfr1.csv", stringsAsFactors = TRUE)
gfr.2 <- read.csv("assignment1_data/ltegfr2.csv", stringsAsFactors = TRUE)
```

#### Problem 2 (a)

Converting the files to data tables and merge in an appropriate way into a single data table
```{r}
eGFR.dt <- merge( data.table(gfr.1),
                 data.table(gfr.2),
                 by.x = c("id","fu.years"), 
                 by.y = c("ID","fu.years"),
                 all = TRUE )
```

Ordering the observations according to subject identifier and follow-up time
```{r}
setorderv(eGFR.dt, c("id","fu.years"), c(1,1))
```

Adding an assertion that the ordering is correct

```{r}
stopifnot( all(eGFR.dt[, c("id", "fu.years")] == eGFR.dt[order(id, fu.years), fu.years, by = id] ))
```

#### Problem 2 (b)

Computing the average eGFR and length of follow-up for each patient:
```{r}
summary.egfr.table <- NULL

for (pat.id in 1:max(eGFR.dt$id)){
  
  # calculate average eGFR for each patient
  avg.egfr <- mean(eGFR.dt[id == pat.id]$egfr, na.rm = TRUE)
  
  # calculate average follow-up for each patient
  avg.fu.years <- mean(eGFR.dt[id == pat.id]$fu.years, na.rm = TRUE)
  
  # create a summary table
  summary.egfr.table <- rbind(summary.egfr.table, c(pat.id, avg.egfr, avg.fu.years))
}

colnames(summary.egfr.table) <- c("pat.id", "avg.gfr", "avg.fu.years") # assign colnames to table
summary.egfr.dt <- data.table(summary.egfr.table) # create data.table
head(summary.egfr.dt)
```

Tabulating the number of patients with average eGFR in the following ranges:
(0, 15], (15, 30], (30, 60], (60, 90], (90, ∞)
```{r}
egfr.bins <- c(0, 15, 30, 60, 90, Inf)
table(cut(summary.egfr.dt$avg.gfr, egfr.bins))
```

Counting and reporting the number of patients with missing average eGFR:
```{r}
# number of patients with missing average eGFR
sum(is.na(summary.egfr.dt$avg.gfr))
```

Ensuring that the table ordering is returned to id, and follow-up time:
Check `eGFR.dt` and `summary.egfr.dt` table:
```{r}
# eGFR.dt
setorderv(eGFR.dt, c("id","fu.years"), c(1,1))
stopifnot( all(eGFR.dt[, c("id", "fu.years")] == eGFR.dt[order(id, fu.years), fu.years, by = id] ))

# summary.egfr.dt
setorderv(summary.egfr.dt, c("pat.id","avg.fu.years"), c(1,1))
stopifnot( all(summary.egfr.dt[, c("pat.id", "avg.fu.years")] == summary.egfr.dt[order(pat.id, avg.fu.years), avg.fu.years, by = pat.id]))
```

Fitting a linear regression model for the eGFR measurements as a function of time 
for each patient with at least 3 eGFR readings and store it in the `summary.egfr.dt` data table
```{r}
# create empty vector
lr.models <- vector(mode="list", length=max(eGFR.dt$id))

# loop over all patients in eGFR data table
for (pat.id in 1:max(eGFR.dt$id)){
  
  # check whether patient has at least 3 eGFR readings
  if (sum(!is.na(eGFR.dt[id == pat.id]$egfr)) >= 3){
    # fit LR model
    regr.egfr <- lm(egfr ~  fu.years, data = eGFR.dt[id == pat.id], na.action = na.omit)
  } else {
    regr.egfr <- NA
  }
  
  lr.models[[pat.id]] <- regr.egfr
  
}

# add LR models to the summary data table
summary.egfr.dt <- cbind(summary.egfr.dt, lr.models)
```

Counting how many patients have a slope < -3, [-3, 0), [0, 3], > 3
```{r}
# Creating slope bins
slope.1 <- 0 # < -3
slope.2 <- 0 # [-3, 0)
slope.3 <- 0 # [0, 3]
slope.4 <- 0 # > 3

# Looping over entries of summary data table
for (id in 1:max(summary.egfr.dt$pat.id)){
  
  # check whether LR model exists
  if (!is.na(summary.egfr.dt[pat.id == id ]$lr.models)){
    
    # assign slope of the model to variable
    slope <- coef(summary.egfr.dt[pat.id == id ]$lr.models[[1]])[2]
    
    # increment the respective bin counter by 1
    if (slope < -3){
      slope.1 <- slope.1 + 1
    } else if (slope >= -3 && slope < 0){
      slope.2 <- slope.2 + 1
    } else if (slope >= 0 && slope <= 3){
      slope.3 <- slope.3 + 1
    } else if (slope > 3){
      slope.4 <- slope.4 + 1
    }
  }
}

# create data table
slopes.dt <- data.table("slope" = c("< -3","[-3, 0)","[0, 3]","> 3"), 
                        "N Patients" = c(slope.1, slope.2, slope.3, slope.4))
slopes.dt
```

#### Problem 2 (c)

For patients with average eGFR in the (0,15] range, collecting their identifier, sex, age at baseline, average eGFR, time of last eGFR reading and number of eGFR measurements taken in a data table:
```{r}
eGFR.le.15 <- NULL

for (i in 1:max(summary.egfr.dt$pat.id)){
  avg.gfr <- summary.egfr.dt[pat.id == i]$avg.gfr

  if (!is.na(avg.gfr) && avg.gfr > 0 && avg.gfr <= 15){
    sex <- eGFR.dt[id == i]$sex[1]
    age <- eGFR.dt[id == i]$baseline.age[1]
    last.egfr <- last(eGFR.dt[id == i]$fu.years)
    egfr.measurements <- sum(!is.na(eGFR.dt[id == i]$egfr))
    
    eGFR.le.15 <- rbind(eGFR.le.15, c(i, sex, age, avg.gfr, last.egfr, egfr.measurements))

  }
  
}

eGFR.le.15.dt <- data.table(eGFR.le.15)
colnames(eGFR.le.15.dt) <- c('Patient ID', 'Sex', 'Age (baseline)', 'average eGFR', 'last eGFR measurments', 'eGFR measurements')

head(eGFR.le.15.dt)
```

#### Problem 2 (d)

For patients 3, 37, 162 and 223 (one at a time):

* ploting the patient’s eGFR measurements as a function of time
* fitting a linear regression model and add the regression line to the plot
* reporting the 95% confidence interval for the regression coefficients of the fitted model
* using a different colour, plot a second regression line computed after removing the
extreme eGFR values (one each of the highest and the lowest value)

```{r}
ids <- c(3, 37, 162, 223)

for(pat in ids){
  
  time <- eGFR.dt[id == pat]$fu.years
  egfr <- eGFR.dt[id == pat]$egfr
  
  time <- time[which(!is.na(egfr))]
  egfr <- egfr[!is.na(egfr)]
  
  # plotting the patient’s eGFR measurements over time
  plot(time, egfr,
       type = "l",
       col = "blue",
       main = paste0('PatientID ', pat ,': eGFR measurements over time'),
       xlab = 'time (years)',
       ylab = 'eGFR (mL/min/1.73 m2)')
  
  # fitting a linear regression model
  fit1 <- lm(egfr ~ time)
  
  # adding regression line to the plot
  abline(coef(fit1)[1], coef(fit1)[2], col="red")
  
  # fitting a 2nd linear regression model without extrem eGFR values
  time <- time[which(egfr > min(egfr) & egfr < max(egfr))]
  egfr <- egfr[egfr > min(egfr) & egfr < max(egfr)]
  
  fit2 <- lm(egfr ~ time)
  
  # adding 2nd regression line to the plot
  abline(coef(fit2)[1], coef(fit2)[2], col="orange")
  
  # legend to do differ fit1 from fit2
  redorange <- c("red","orange")
  legend("bottomleft", c("before removal", "after removal"), fill = redorange)
  
  # reporting  95% CI for the regression coefficients of fit 1
  print("95% CI for regression coefficients before removal")
  print(confint(fit1))
  
  # reporting  95% CI for the regression coefficients of fit 2
  print("95% CI for regression coefficients after removal")
  print(confint(fit2))
  
}
```

### Problem 3

#### Problem 3 (a)

Writing an R6 class `Calcegfr` that accepts 4 vectors: serum creatinine (`scr`), age (`age`), sex (`sex`) and ethnicity (`ethnic`). 
The initialisation method of the class validates that vector lengths match and stores them for use by the methods. The class then implements two separate public methods of the two eGFR formulas, MDRD4 and CKD-EPI, and stores the result as a vector of the same length as the input.

```{r}
library(R6)

Calcegfr <- R6Class("Calcegfr", public = list(
  scr = vector(),
  age = vector(),
  sex = factor(),
  ethnic = factor(),
  mdrd4.egfr = vector(),
  ckdepi.egfr = vector(),
  
  # initalisation method
  initialize = function(scr, age, sex, ethnic){
    
    # input data checks
    
    # check whether vector lengths match
    stopifnot(length(scr) == length(age) &&
              length(scr) == length(sex) &&
              length(scr) == length(ethnic))
    
    # check whether scr and age are numeric
    stopifnot(is.numeric(scr) && is.numeric(age))
    
    # check whether sex and ethnic are factors 
    stopifnot(is.factor(sex) && is.factor(ethnic))
    
    # initialise member variables
    
    self$scr <- scr
    self$age <- age
    self$sex <- sex
    self$ethnic <- ethnic
    
    self$mdrd4.egfr <- numeric(length = length(self$scr))
    self$ckdepi.egfr <- numeric(length = length(self$scr))
    
  }, 
  
  # estimating GFR with MDRD4 equation
  
  egfr.mdrd4 = function(){
    scr <- self$scr
    age <- self$age
    sex <- self$sex
    ethnic <- self$ethnic
    
    # converting levels of factor variables
    
    sex <- ifelse( sex == "Female", 0.742, 1)
    ethnic <- ifelse( ethnic == "Black", 1.212, 1)
    
    # main body
    
    self$mdrd4.egfr <- 175*(scr/88.42)^(-1.154)*age^(-0.203)*sex*ethnic
    
    # return
    return(self$mdrd4.egfr)
  },
  
  # estimating GFR with CKD-EPI equation
  
  egfr.ckdepi = function(){
    scr <- self$scr
    age <- self$age
    sex <- self$sex
    ethnic <- self$ethnic
    
    # calculating alpha and kappa
    
    alpha <- ifelse( sex == "Female", -0.329, -0.411)
    kappa <- ifelse( sex == "Female", 0.7, 0.9)
    
    # converting levels of factor variables

    sex <- ifelse( sex == "Female", 1.018, 1)
    ethnic <- ifelse( ethnic == "Black", 1.159, 1)
  
    # main body
    
    self$ckdepi.egfr <- 141*pmin((scr/88.42)/kappa, 1)^alpha*pmax((scr/88.42)/kappa, 1)^(-1.209)*0.993^(age)*sex*ethnic
    
    # return results
    return(self$ckdepi.egfr)
  }
    
))
```

#### Problem 3 (b)

Loading the `scr2.csv` dataset, creating a `Calcegfr` object and computing the eGFR according to the MDRD4 and CKD-EPI equations:
```{r}
# load data set
scr2 <- read.csv("assignment1_data/scr2.csv", stringsAsFactors = TRUE)

# create an Calcegfr object
scr2.calcegfr <- Calcegfr$new(scr2$scr, scr2$age, scr2$sex, scr2$ethnic)

# compute the eGFR according to the two equations
mdrd4.egfr <- scr2.calcegfr$egfr.mdrd4()
ckdepi.egfr <- scr2.calcegfr$egfr.ckdepi()
```

Computing mean and SD of the MDRD4 and CKD EPI results (rounded to the second decimal place):
```{r}
# mean of MDRD4 results
round(mean(mdrd4.egfr, na.rm = TRUE),2)
# SD of MDRD4 results
round(sd(mdrd4.egfr, na.rm = TRUE),2)

# mean of CKD-EPI results
round(mean(ckdepi.egfr, na.rm = TRUE),2)
# SD of CKD-EPI results
round(sd(ckdepi.egfr, na.rm = TRUE),2)
```
Computing Pearson's correlation coefficient between both eGFR results
```{r}
round(cor(mdrd4.egfr, ckdepi.egfr, method = "pearson", use = "complete.obs"),2)
```

Reporting the mean and SD for all patients with eGFRs between 0-60, 60-90 and > 90 according to MDRD4:
```{r}
# create eGFR bins
egfr.bins <- c(0, 60, 90, Inf)

# subset MDRD results according to bins
mdrd4.egfr.low <- mdrd4.egfr[which(cut(mdrd4.egfr, egfr.bins) == "(0,60]")]
mdrd4.egfr.med <- mdrd4.egfr[which(cut(mdrd4.egfr, egfr.bins) == "(60,90]")]
mdrd4.egfr.high <- mdrd4.egfr[which(cut(mdrd4.egfr, egfr.bins) == "(90,Inf]")]

# calculate mean and SD for all 3 bins
low.mean <- round(mean(mdrd4.egfr.low, na.rm = TRUE),2)
low.SD <- round(sd(mdrd4.egfr.low, na.rm = TRUE),2)

med.mean <- round(mean(mdrd4.egfr.med, na.rm = TRUE),2)
med.SD <- round(sd(mdrd4.egfr.med, na.rm = TRUE),2)

high.mean <- round(mean(mdrd4.egfr.high, na.rm = TRUE),2)
high.SD <- round(sd(mdrd4.egfr.high, na.rm = TRUE),2)

# create sumamry table of MDRD4 eGFR
mdrd4.summary.dt <- data.table("eGFR" = c("(0,60]","(60,90]", "(90,Inf]"),
                               "N" = c(length(mdrd4.egfr.low), length(mdrd4.egfr.med), length(mdrd4.egfr.high)),
                               "Mean" = c(low.mean, med.mean, high.mean),
                               "SD" = c(low.SD, med.SD, high.SD))

mdrd4.summary.dt
```

### Problem 4